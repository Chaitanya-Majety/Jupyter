{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tensorflow_Softmax_Classifier.ipynb","provenance":[{"file_id":"1cYvTo2mcBpBU2XIihDhbDUGrfrkzwgCp","timestamp":1643816592238}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UhNRn7pEro8w"},"source":["# Softmax Classifier using TensorFlow 1.X"]},{"cell_type":"code","source":["%tensorflow_version 1.x"],"metadata":{"id":"xLx5zNCGCGtv","executionInfo":{"status":"ok","timestamp":1644162992912,"user_tz":-330,"elapsed":462,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}},"outputId":"70b1fa89-a19f-4ca5-a4cf-f6b56a1c8486","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n"]}]},{"cell_type":"code","source":["import tensorflow\n","print(tensorflow.__version__)"],"metadata":{"id":"t1ZBe-ZKCZyz","executionInfo":{"status":"ok","timestamp":1644162997721,"user_tz":-330,"elapsed":3369,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}},"outputId":"8a22d26a-87f5-40f0-ca1d-8d6b59b5991f","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["1.15.2\n"]}]},{"cell_type":"code","metadata":{"id":"QAuadyaFro80","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644163000040,"user_tz":-330,"elapsed":2321,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}},"outputId":"fe8d88d8-e4f2-4513-bf36-f201b998316b"},"source":["# credits: https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners\n","import tensorflow\n","from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From <ipython-input-3-7265c405c75f>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"]}]},{"cell_type":"code","metadata":{"id":"3nD4hN9Gro9L","executionInfo":{"status":"ok","timestamp":1644163000041,"user_tz":-330,"elapsed":9,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}}},"source":["import numpy as np"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-p1oHQDVro9U"},"source":["<p>\n","Every MNIST data point has two parts: an image of a handwritten digit and a corresponding label. We'll call the images \"x\" and the labels \"y\". Both the training set and test set contain images and their corresponding labels; for example the training images are mnist.train.images and the training labels are mnist.train.labels.\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"-MS3H9-Kro9W"},"source":["<p>\n","mnist.train.images is a tensor (an n-dimensional array) with a shape of [55000, 784]. The first dimension is an index into the list of images and the second dimension is the index for each pixel in each image. Each entry in the tensor is a pixel intensity between 0 and 1, for a particular pixel in a particular image.\n","</p>"]},{"cell_type":"code","metadata":{"id":"_v5ltd4uro9Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644163000041,"user_tz":-330,"elapsed":8,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}},"outputId":"34301788-afa8-4e10-aa10-5357b73127da"},"source":["print(\"number of data points : \", mnist.train.images.shape[0],\"number of pixels in each image :\",mnist.train.images.shape[1])"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["number of data points :  55000 number of pixels in each image : 784\n"]}]},{"cell_type":"markdown","metadata":{"id":"GgaHugyNro9i"},"source":["<p>\n","we're going to want our class-labels as \"one-hot vectors\". A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In this case, the t-th digit will be represented as a vector which is 1 in the t-th dimension. For example, 3 would be [0,0,0,1,0,0,0,0,0,0]. Consequently, mnist.train.labels is a [55000, 10] array of floats.\n","</p>"]},{"cell_type":"code","metadata":{"id":"IwEk7I3iro9k","outputId":"0cc7805f-30e2-40c4-de4e-3a8c7be0aa30","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644163000042,"user_tz":-330,"elapsed":6,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}}},"source":["print(\"number of data points : \", mnist.test.labels.shape[0],\" length of the one hot encoded label vector :\",mnist.test.labels.shape[1])"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["number of data points :  10000  length of the one hot encoded label vector : 10\n"]}]},{"cell_type":"markdown","metadata":{"id":"_iquBvcxro9s"},"source":["<p>\n","If you want to assign probabilities to an object being one of several different things, softmax (Multiclass Logistic regression) is the thing to do, because softmax gives us a list of values between 0 and 1 that add up to 1. Even later on, when we train more sophisticated models, the final step will be a layer of softmax.\n","\n","A softmax regression has two steps: first we add up the evidence of our input being in certain classes, and then we convert that evidence into probabilities.\n","</p>"]},{"cell_type":"code","metadata":{"id":"4RiPinIxro9u","executionInfo":{"status":"ok","timestamp":1644163000042,"user_tz":-330,"elapsed":5,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}}},"source":["import tensorflow as tf"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"5sFc2FZcro9y","outputId":"5bb8eddb-1111-4e3e-bfdf-fc52372d04c8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644163000730,"user_tz":-330,"elapsed":693,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}}},"source":["# Get a list of devices like GPUs and CPUs available to TF\n","\n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 10466412957898763472\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 269251520207791940\n","physical_device_desc: \"device: XLA_CPU device\"\n","]\n"]}]},{"cell_type":"markdown","metadata":{"id":"Me4O2pkUro93"},"source":["\n","Sample Output (with a GPU) <br>\n","\n","[name: \"/cpu:0\" device_type: \"CPU\" memory_limit: 268435456 locality { } incarnation: 4402277519343584096,\n","\n","name: \"/gpu:0\" device_type: \"GPU\" memory_limit: 6772842168 locality { bus_id: 1 } incarnation: 7471795903849088328 physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0\" ]"]},{"cell_type":"markdown","metadata":{"id":"fQeukILEro94"},"source":["### Placeholders and Variables"]},{"cell_type":"code","metadata":{"id":"dSl4cllIro95","executionInfo":{"status":"ok","timestamp":1644163000731,"user_tz":-330,"elapsed":5,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}}},"source":["# x isn't a specific value. It's a placeholder. A placeholder can be imagained as \n","# a memory unit that we use to load various mini-batches of imput data while training.\n","\n","\n","# We want to be able to input any number of MNIST images, \n","# each flattened into a 784-dimensional vector. \n","\n","# We represent this as a 2-D tensor of floating-point numbers, \n","# with a shape [None, 784]. \n","\n","# (Here None means that a dimension can be of any length.)\n","x = tf.placeholder(tf.float32, [None, 784]) ## means we are creating a empty space for future purpose\n","\n","# We also need the weights and biases for our model. \n","\n","# We could imagine treating these like additional inputs, \n","# but TensorFlow has an even better way to handle it: Variable. \n","\n","# A Variable is a modifiable tensor that lives in TensorFlow's graph\n","# of interacting operations. \n","\n","# It can be used and even modified by the computation. \n","# For machine learning applications, one generally has the model parameters be Variables.\n","W = tf.Variable(tf.zeros([784, 10]))\n","b = tf.Variable(tf.zeros([10]))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6IQPfMero98","executionInfo":{"status":"ok","timestamp":1644163000732,"user_tz":-330,"elapsed":5,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}}},"source":["# First, we multiply x by W with the expression tf.matmul(x, W). \n","# This is flipped from when we multiplied them in our equation, \n","# where we had Wx , as a small trick to deal with x being a 2D tensor \n","# with multiple inputs. \n","\n","# We then add b, and finally apply tf.nn.softmax.\n","y = tf.nn.softmax(tf.matmul(x, W) + b)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"kabqZYcaro9_","executionInfo":{"status":"ok","timestamp":1644163010366,"user_tz":-330,"elapsed":512,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}}},"source":["# y_ is true label of the images, and similar to x\n","y_ = tf.placeholder(tf.float32, [None, 10])\n","\n","\n","# Defining the loss function: multi class log-loss/cross-entropy\n","# First, tf.log computes the logarithm of each element of y. \n","\n","# Next, we multiply each element of y_ with the corresponding element \n","# of tf.log(y). \n","\n","# Then tf.reduce_sum adds the elements in the second dimension of y, \n","# due to the reduction_indices=[1] parameter. \n","\n","#Tutorial for tf.reduce_sum: https://www.dotnetperls.com/reduce-sum-tensorflow\n","\n","# Reduction is an operation that removes one or more dimensions from a tensor by performing \n","# certain operations across those dimensions.\n","\n","# Finally, tf.reduce_mean computes the mean over all the examples in the batch.\n","cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"vREdzNYPro-D","executionInfo":{"status":"ok","timestamp":1644163060333,"user_tz":-330,"elapsed":421,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}}},"source":["# In this case, we ask TensorFlow to minimize cross_entropy \n","# using the gradient descent algorithm with a learning rate of 0.05.\n","\n","# https://www.tensorflow.org/versions/r1.2/api_guides/python/train#Optimizers\n","\n","train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)\n","# This means my training should be done using Gradient descent optimizer which minimizes the cross entropy\n","\n","# What TensorFlow actually does here, behind the scenes,\n","# is to add new operations to your computation-graph which implement backpropagation and gradient descent.\n","# Then it gives you back a single operation which, when run, does a step of gradient descent training, \n","# slightly tweaking your variables to reduce the loss."],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"7DmJqAN3ro-I","executionInfo":{"status":"ok","timestamp":1644163083959,"user_tz":-330,"elapsed":6,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}}},"source":["# We can now launch the model in an InteractiveSession\n","sess = tf.InteractiveSession()\n","\n","# We first have to create an operation to initialize the \n","# variables we created:\n","tf.global_variables_initializer().run()"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9dHQaw-ro-M","executionInfo":{"status":"ok","timestamp":1644163091287,"user_tz":-330,"elapsed":2270,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}}},"source":["# Each step of the loop, we get a \"mini-batch\" of one hundred random data \n","# points from our training set. \n","\n","# We run train_step feeding in the batches data to replace \n","# the placeholders\n","for _ in range(1000):\n","    batch_xs, batch_ys = mnist.train.next_batch(100)\n","    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n","\n","# Using small batches of random data is called stochastic training -- in this case, stochastic gradient descent. \n","# Ideally, we'd like to use all our data for every step of training because that would give us a better sense of\n","# what we should be doing, but that's expensive. So, instead, we use a different subset every time. \n","# Doing this is cheap and has much of the same benefit."],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"02cd-K4uro-Q","outputId":"979e2531-914d-4a7c-e91d-9fd7f817cc48","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644163098980,"user_tz":-330,"elapsed":1055,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}}},"source":["# https://stackoverflow.com/a/41863099\n","# tf.argmax(input, axis=None, name=None, dimension=None)\n","# Returns the index with the largest value across axis of a tensor(for all the rows).\n","correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","# this will have the all the rows data at a single vector, so length of this vecor will be equal to the dataset\n","\n","# Here session contains the network information and corresponding weights in it. So now when you run session.run(test data), the test data will be fed into this network.\n","print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9\n"]}]},{"cell_type":"code","metadata":{"id":"Ian22lpAro-V","executionInfo":{"status":"ok","timestamp":1644163103370,"user_tz":-330,"elapsed":4,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}}},"source":["%matplotlib notebook\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import time\n","# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\n","# https://stackoverflow.com/a/14434334\n","def plt_dynamic(x, y, y_1, ax, colors=['b']):\n","    ax.plot(x, y, 'b', label=\"Train Loss\")\n","    ax.plot(x, y_1, 'r', label=\"Test Loss\")\n","    if len(x)==1:\n","        plt.legend()\n","    fig.canvas.draw()"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"6ECWKXHiro-b","outputId":"9e70f5ef-32a0-4898-87a3-a3638c665632","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1644163123639,"user_tz":-330,"elapsed":12652,"user":{"displayName":"chaitanya Majety","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpm7aj9Vdc5JW6pfVAN3Tl4VfpaI1wNqM4bNyh=s64","userId":"01300610858939111436"}}},"source":["# summarizing everything in single cell\n","training_epochs = 15\n","batch_size = 1000\n","display_step = 1\n","cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y, labels = y_))\n","train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)\n","\n","fig,ax = plt.subplots(1,1)\n","ax.set_xlabel('epoch') ; ax.set_ylabel('Soft Max Cross Entropy loss')\n","xs, ytrs, ytes = [], [], []\n","for epoch in range(training_epochs):\n","        train_avg_cost = 0.\n","        test_avg_cost = 0.\n","        total_batch = int(mnist.train.num_examples/batch_size)\n","        # Loop over all batches\n","        for i in range(total_batch):\n","            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n","            _, c = sess.run([train_step, cross_entropy], feed_dict={x: batch_xs, y_: batch_ys})\n","            train_avg_cost += c / total_batch\n","            c = sess.run(cross_entropy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n","            test_avg_cost += c / total_batch\n","\n","        xs.append(epoch)\n","        ytrs.append(train_avg_cost)\n","        ytes.append(test_avg_cost)\n","        plt_dynamic(xs, ytrs, ytes, ax)\n","        \n","\n","plt_dynamic(xs, ytrs, ytes, ax)\n","correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y_: mnist.test.labels}))"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From <ipython-input-17-7cb9314abf57>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n"]},{"output_type":"display_data","data":{"application/javascript":["/* Put everything inside the global mpl namespace */\n","window.mpl = {};\n","\n","\n","mpl.get_websocket_type = function() {\n","    if (typeof(WebSocket) !== 'undefined') {\n","        return WebSocket;\n","    } else if (typeof(MozWebSocket) !== 'undefined') {\n","        return MozWebSocket;\n","    } else {\n","        alert('Your browser does not have WebSocket support. ' +\n","              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n","              'Firefox 4 and 5 are also supported but you ' +\n","              'have to enable WebSockets in about:config.');\n","    };\n","}\n","\n","mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n","    this.id = figure_id;\n","\n","    this.ws = websocket;\n","\n","    this.supports_binary = (this.ws.binaryType != undefined);\n","\n","    if (!this.supports_binary) {\n","        var warnings = document.getElementById(\"mpl-warnings\");\n","        if (warnings) {\n","            warnings.style.display = 'block';\n","            warnings.textContent = (\n","                \"This browser does not support binary websocket messages. \" +\n","                    \"Performance may be slow.\");\n","        }\n","    }\n","\n","    this.imageObj = new Image();\n","\n","    this.context = undefined;\n","    this.message = undefined;\n","    this.canvas = undefined;\n","    this.rubberband_canvas = undefined;\n","    this.rubberband_context = undefined;\n","    this.format_dropdown = undefined;\n","\n","    this.image_mode = 'full';\n","\n","    this.root = $('<div/>');\n","    this._root_extra_style(this.root)\n","    this.root.attr('style', 'display: inline-block');\n","\n","    $(parent_element).append(this.root);\n","\n","    this._init_header(this);\n","    this._init_canvas(this);\n","    this._init_toolbar(this);\n","\n","    var fig = this;\n","\n","    this.waiting = false;\n","\n","    this.ws.onopen =  function () {\n","            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n","            fig.send_message(\"send_image_mode\", {});\n","            if (mpl.ratio != 1) {\n","                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n","            }\n","            fig.send_message(\"refresh\", {});\n","        }\n","\n","    this.imageObj.onload = function() {\n","            if (fig.image_mode == 'full') {\n","                // Full images could contain transparency (where diff images\n","                // almost always do), so we need to clear the canvas so that\n","                // there is no ghosting.\n","                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n","            }\n","            fig.context.drawImage(fig.imageObj, 0, 0);\n","        };\n","\n","    this.imageObj.onunload = function() {\n","        fig.ws.close();\n","    }\n","\n","    this.ws.onmessage = this._make_on_message_function(this);\n","\n","    this.ondownload = ondownload;\n","}\n","\n","mpl.figure.prototype._init_header = function() {\n","    var titlebar = $(\n","        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n","        'ui-helper-clearfix\"/>');\n","    var titletext = $(\n","        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n","        'text-align: center; padding: 3px;\"/>');\n","    titlebar.append(titletext)\n","    this.root.append(titlebar);\n","    this.header = titletext[0];\n","}\n","\n","\n","\n","mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n","\n","}\n","\n","\n","mpl.figure.prototype._root_extra_style = function(canvas_div) {\n","\n","}\n","\n","mpl.figure.prototype._init_canvas = function() {\n","    var fig = this;\n","\n","    var canvas_div = $('<div/>');\n","\n","    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n","\n","    function canvas_keyboard_event(event) {\n","        return fig.key_event(event, event['data']);\n","    }\n","\n","    canvas_div.keydown('key_press', canvas_keyboard_event);\n","    canvas_div.keyup('key_release', canvas_keyboard_event);\n","    this.canvas_div = canvas_div\n","    this._canvas_extra_style(canvas_div)\n","    this.root.append(canvas_div);\n","\n","    var canvas = $('<canvas/>');\n","    canvas.addClass('mpl-canvas');\n","    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n","\n","    this.canvas = canvas[0];\n","    this.context = canvas[0].getContext(\"2d\");\n","\n","    var backingStore = this.context.backingStorePixelRatio ||\n","\tthis.context.webkitBackingStorePixelRatio ||\n","\tthis.context.mozBackingStorePixelRatio ||\n","\tthis.context.msBackingStorePixelRatio ||\n","\tthis.context.oBackingStorePixelRatio ||\n","\tthis.context.backingStorePixelRatio || 1;\n","\n","    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n","\n","    var rubberband = $('<canvas/>');\n","    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n","\n","    var pass_mouse_events = true;\n","\n","    canvas_div.resizable({\n","        start: function(event, ui) {\n","            pass_mouse_events = false;\n","        },\n","        resize: function(event, ui) {\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","        stop: function(event, ui) {\n","            pass_mouse_events = true;\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","    });\n","\n","    function mouse_event_fn(event) {\n","        if (pass_mouse_events)\n","            return fig.mouse_event(event, event['data']);\n","    }\n","\n","    rubberband.mousedown('button_press', mouse_event_fn);\n","    rubberband.mouseup('button_release', mouse_event_fn);\n","    // Throttle sequential mouse events to 1 every 20ms.\n","    rubberband.mousemove('motion_notify', mouse_event_fn);\n","\n","    rubberband.mouseenter('figure_enter', mouse_event_fn);\n","    rubberband.mouseleave('figure_leave', mouse_event_fn);\n","\n","    canvas_div.on(\"wheel\", function (event) {\n","        event = event.originalEvent;\n","        event['data'] = 'scroll'\n","        if (event.deltaY < 0) {\n","            event.step = 1;\n","        } else {\n","            event.step = -1;\n","        }\n","        mouse_event_fn(event);\n","    });\n","\n","    canvas_div.append(canvas);\n","    canvas_div.append(rubberband);\n","\n","    this.rubberband = rubberband;\n","    this.rubberband_canvas = rubberband[0];\n","    this.rubberband_context = rubberband[0].getContext(\"2d\");\n","    this.rubberband_context.strokeStyle = \"#000000\";\n","\n","    this._resize_canvas = function(width, height) {\n","        // Keep the size of the canvas, canvas container, and rubber band\n","        // canvas in synch.\n","        canvas_div.css('width', width)\n","        canvas_div.css('height', height)\n","\n","        canvas.attr('width', width * mpl.ratio);\n","        canvas.attr('height', height * mpl.ratio);\n","        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n","\n","        rubberband.attr('width', width);\n","        rubberband.attr('height', height);\n","    }\n","\n","    // Set the figure to an initial 600x600px, this will subsequently be updated\n","    // upon first draw.\n","    this._resize_canvas(600, 600);\n","\n","    // Disable right mouse context menu.\n","    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n","        return false;\n","    });\n","\n","    function set_focus () {\n","        canvas.focus();\n","        canvas_div.focus();\n","    }\n","\n","    window.setTimeout(set_focus, 100);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items) {\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) {\n","            // put a spacer in here.\n","            continue;\n","        }\n","        var button = $('<button/>');\n","        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n","                        'ui-button-icon-only');\n","        button.attr('role', 'button');\n","        button.attr('aria-disabled', 'false');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","\n","        var icon_img = $('<span/>');\n","        icon_img.addClass('ui-button-icon-primary ui-icon');\n","        icon_img.addClass(image);\n","        icon_img.addClass('ui-corner-all');\n","\n","        var tooltip_span = $('<span/>');\n","        tooltip_span.addClass('ui-button-text');\n","        tooltip_span.html(tooltip);\n","\n","        button.append(icon_img);\n","        button.append(tooltip_span);\n","\n","        nav_element.append(button);\n","    }\n","\n","    var fmt_picker_span = $('<span/>');\n","\n","    var fmt_picker = $('<select/>');\n","    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n","    fmt_picker_span.append(fmt_picker);\n","    nav_element.append(fmt_picker_span);\n","    this.format_dropdown = fmt_picker[0];\n","\n","    for (var ind in mpl.extensions) {\n","        var fmt = mpl.extensions[ind];\n","        var option = $(\n","            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n","        fmt_picker.append(option);\n","    }\n","\n","    // Add hover states to the ui-buttons\n","    $( \".ui-button\" ).hover(\n","        function() { $(this).addClass(\"ui-state-hover\");},\n","        function() { $(this).removeClass(\"ui-state-hover\");}\n","    );\n","\n","    var status_bar = $('<span class=\"mpl-message\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","}\n","\n","mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n","    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n","    // which will in turn request a refresh of the image.\n","    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n","}\n","\n","mpl.figure.prototype.send_message = function(type, properties) {\n","    properties['type'] = type;\n","    properties['figure_id'] = this.id;\n","    this.ws.send(JSON.stringify(properties));\n","}\n","\n","mpl.figure.prototype.send_draw_message = function() {\n","    if (!this.waiting) {\n","        this.waiting = true;\n","        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n","    }\n","}\n","\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    var format_dropdown = fig.format_dropdown;\n","    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n","    fig.ondownload(fig, format);\n","}\n","\n","\n","mpl.figure.prototype.handle_resize = function(fig, msg) {\n","    var size = msg['size'];\n","    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n","        fig._resize_canvas(size[0], size[1]);\n","        fig.send_message(\"refresh\", {});\n","    };\n","}\n","\n","mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n","    var x0 = msg['x0'] / mpl.ratio;\n","    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n","    var x1 = msg['x1'] / mpl.ratio;\n","    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n","    x0 = Math.floor(x0) + 0.5;\n","    y0 = Math.floor(y0) + 0.5;\n","    x1 = Math.floor(x1) + 0.5;\n","    y1 = Math.floor(y1) + 0.5;\n","    var min_x = Math.min(x0, x1);\n","    var min_y = Math.min(y0, y1);\n","    var width = Math.abs(x1 - x0);\n","    var height = Math.abs(y1 - y0);\n","\n","    fig.rubberband_context.clearRect(\n","        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n","\n","    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n","}\n","\n","mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n","    // Updates the figure title.\n","    fig.header.textContent = msg['label'];\n","}\n","\n","mpl.figure.prototype.handle_cursor = function(fig, msg) {\n","    var cursor = msg['cursor'];\n","    switch(cursor)\n","    {\n","    case 0:\n","        cursor = 'pointer';\n","        break;\n","    case 1:\n","        cursor = 'default';\n","        break;\n","    case 2:\n","        cursor = 'crosshair';\n","        break;\n","    case 3:\n","        cursor = 'move';\n","        break;\n","    }\n","    fig.rubberband_canvas.style.cursor = cursor;\n","}\n","\n","mpl.figure.prototype.handle_message = function(fig, msg) {\n","    fig.message.textContent = msg['message'];\n","}\n","\n","mpl.figure.prototype.handle_draw = function(fig, msg) {\n","    // Request the server to send over a new figure.\n","    fig.send_draw_message();\n","}\n","\n","mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n","    fig.image_mode = msg['mode'];\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Called whenever the canvas gets updated.\n","    this.send_message(\"ack\", {});\n","}\n","\n","// A function to construct a web socket function for onmessage handling.\n","// Called in the figure constructor.\n","mpl.figure.prototype._make_on_message_function = function(fig) {\n","    return function socket_on_message(evt) {\n","        if (evt.data instanceof Blob) {\n","            /* FIXME: We get \"Resource interpreted as Image but\n","             * transferred with MIME type text/plain:\" errors on\n","             * Chrome.  But how to set the MIME type?  It doesn't seem\n","             * to be part of the websocket stream */\n","            evt.data.type = \"image/png\";\n","\n","            /* Free the memory for the previous frames */\n","            if (fig.imageObj.src) {\n","                (window.URL || window.webkitURL).revokeObjectURL(\n","                    fig.imageObj.src);\n","            }\n","\n","            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n","                evt.data);\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n","            fig.imageObj.src = evt.data;\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","\n","        var msg = JSON.parse(evt.data);\n","        var msg_type = msg['type'];\n","\n","        // Call the  \"handle_{type}\" callback, which takes\n","        // the figure and JSON message as its only arguments.\n","        try {\n","            var callback = fig[\"handle_\" + msg_type];\n","        } catch (e) {\n","            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n","            return;\n","        }\n","\n","        if (callback) {\n","            try {\n","                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n","                callback(fig, msg);\n","            } catch (e) {\n","                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n","            }\n","        }\n","    };\n","}\n","\n","// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n","mpl.findpos = function(e) {\n","    //this section is from http://www.quirksmode.org/js/events_properties.html\n","    var targ;\n","    if (!e)\n","        e = window.event;\n","    if (e.target)\n","        targ = e.target;\n","    else if (e.srcElement)\n","        targ = e.srcElement;\n","    if (targ.nodeType == 3) // defeat Safari bug\n","        targ = targ.parentNode;\n","\n","    // jQuery normalizes the pageX and pageY\n","    // pageX,Y are the mouse positions relative to the document\n","    // offset() returns the position of the element relative to the document\n","    var x = e.pageX - $(targ).offset().left;\n","    var y = e.pageY - $(targ).offset().top;\n","\n","    return {\"x\": x, \"y\": y};\n","};\n","\n","/*\n"," * return a copy of an object with only non-object keys\n"," * we need this to avoid circular references\n"," * http://stackoverflow.com/a/24161582/3208463\n"," */\n","function simpleKeys (original) {\n","  return Object.keys(original).reduce(function (obj, key) {\n","    if (typeof original[key] !== 'object')\n","        obj[key] = original[key]\n","    return obj;\n","  }, {});\n","}\n","\n","mpl.figure.prototype.mouse_event = function(event, name) {\n","    var canvas_pos = mpl.findpos(event)\n","\n","    if (name === 'button_press')\n","    {\n","        this.canvas.focus();\n","        this.canvas_div.focus();\n","    }\n","\n","    var x = canvas_pos.x * mpl.ratio;\n","    var y = canvas_pos.y * mpl.ratio;\n","\n","    this.send_message(name, {x: x, y: y, button: event.button,\n","                             step: event.step,\n","                             guiEvent: simpleKeys(event)});\n","\n","    /* This prevents the web browser from automatically changing to\n","     * the text insertion cursor when the button is pressed.  We want\n","     * to control all of the cursor setting manually through the\n","     * 'cursor' event from matplotlib */\n","    event.preventDefault();\n","    return false;\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    // Handle any extra behaviour associated with a key event\n","}\n","\n","mpl.figure.prototype.key_event = function(event, name) {\n","\n","    // Prevent repeat events\n","    if (name == 'key_press')\n","    {\n","        if (event.which === this._key)\n","            return;\n","        else\n","            this._key = event.which;\n","    }\n","    if (name == 'key_release')\n","        this._key = null;\n","\n","    var value = '';\n","    if (event.ctrlKey && event.which != 17)\n","        value += \"ctrl+\";\n","    if (event.altKey && event.which != 18)\n","        value += \"alt+\";\n","    if (event.shiftKey && event.which != 16)\n","        value += \"shift+\";\n","\n","    value += 'k';\n","    value += event.which.toString();\n","\n","    this._key_event_extra(event, name);\n","\n","    this.send_message(name, {key: value,\n","                             guiEvent: simpleKeys(event)});\n","    return false;\n","}\n","\n","mpl.figure.prototype.toolbar_button_onclick = function(name) {\n","    if (name == 'download') {\n","        this.handle_save(this, null);\n","    } else {\n","        this.send_message(\"toolbar_button\", {name: name});\n","    }\n","};\n","\n","mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n","    this.message.textContent = tooltip;\n","};\n","mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n","\n","mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n","\n","mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n","    // Create a \"websocket\"-like object which calls the given IPython comm\n","    // object with the appropriate methods. Currently this is a non binary\n","    // socket, so there is still some room for performance tuning.\n","    var ws = {};\n","\n","    ws.close = function() {\n","        comm.close()\n","    };\n","    ws.send = function(m) {\n","        //console.log('sending', m);\n","        comm.send(m);\n","    };\n","    // Register the callback with on_msg.\n","    comm.on_msg(function(msg) {\n","        //console.log('receiving', msg['content']['data'], msg);\n","        // Pass the mpl event to the overridden (by mpl) onmessage function.\n","        ws.onmessage(msg['content']['data'])\n","    });\n","    return ws;\n","}\n","\n","mpl.mpl_figure_comm = function(comm, msg) {\n","    // This is the function which gets called when the mpl process\n","    // starts-up an IPython Comm through the \"matplotlib\" channel.\n","\n","    var id = msg.content.data.id;\n","    // Get hold of the div created by the display call when the Comm\n","    // socket was opened in Python.\n","    var element = $(\"#\" + id);\n","    var ws_proxy = comm_websocket_adapter(comm)\n","\n","    function ondownload(figure, format) {\n","        window.open(figure.imageObj.src);\n","    }\n","\n","    var fig = new mpl.figure(id, ws_proxy,\n","                           ondownload,\n","                           element.get(0));\n","\n","    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n","    // web socket which is closed, not our websocket->open comm proxy.\n","    ws_proxy.onopen();\n","\n","    fig.parent_element = element.get(0);\n","    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n","    if (!fig.cell_info) {\n","        console.error(\"Failed to find cell for figure\", id, fig);\n","        return;\n","    }\n","\n","    var output_index = fig.cell_info[2]\n","    var cell = fig.cell_info[0];\n","\n","};\n","\n","mpl.figure.prototype.handle_close = function(fig, msg) {\n","    var width = fig.canvas.width/mpl.ratio\n","    fig.root.unbind('remove')\n","\n","    // Update the output cell to use the data from the current canvas.\n","    fig.push_to_output();\n","    var dataURL = fig.canvas.toDataURL();\n","    // Re-enable the keyboard manager in IPython - without this line, in FF,\n","    // the notebook keyboard shortcuts fail.\n","    IPython.keyboard_manager.enable()\n","    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n","    fig.close_ws(fig, msg);\n","}\n","\n","mpl.figure.prototype.close_ws = function(fig, msg){\n","    fig.send_message('closing', msg);\n","    // fig.ws.close()\n","}\n","\n","mpl.figure.prototype.push_to_output = function(remove_interactive) {\n","    // Turn the data on the canvas into data in the output cell.\n","    var width = this.canvas.width/mpl.ratio\n","    var dataURL = this.canvas.toDataURL();\n","    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Tell IPython that the notebook contents must change.\n","    IPython.notebook.set_dirty(true);\n","    this.send_message(\"ack\", {});\n","    var fig = this;\n","    // Wait a second, then push the new image to the DOM so\n","    // that it is saved nicely (might be nice to debounce this).\n","    setTimeout(function () { fig.push_to_output() }, 1000);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items){\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) { continue; };\n","\n","        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","        nav_element.append(button);\n","    }\n","\n","    // Add the status bar.\n","    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","\n","    // Add the close button to the window.\n","    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n","    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n","    button.click(function (evt) { fig.handle_close(fig, {}); } );\n","    button.mouseover('Stop Interaction', toolbar_mouse_event);\n","    buttongrp.append(button);\n","    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n","    titlebar.prepend(buttongrp);\n","}\n","\n","mpl.figure.prototype._root_extra_style = function(el){\n","    var fig = this\n","    el.on(\"remove\", function(){\n","\tfig.close_ws(fig, {});\n","    });\n","}\n","\n","mpl.figure.prototype._canvas_extra_style = function(el){\n","    // this is important to make the div 'focusable\n","    el.attr('tabindex', 0)\n","    // reach out to IPython and tell the keyboard manager to turn it's self\n","    // off when our div gets focus\n","\n","    // location in version 3\n","    if (IPython.notebook.keyboard_manager) {\n","        IPython.notebook.keyboard_manager.register_events(el);\n","    }\n","    else {\n","        // location in version 2\n","        IPython.keyboard_manager.register_events(el);\n","    }\n","\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    var manager = IPython.notebook.keyboard_manager;\n","    if (!manager)\n","        manager = IPython.keyboard_manager;\n","\n","    // Check for shift+enter\n","    if (event.shiftKey && event.which == 13) {\n","        this.canvas_div.blur();\n","        // select the cell after this one\n","        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n","        IPython.notebook.select(index + 1);\n","    }\n","}\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    fig.ondownload(fig, null);\n","}\n","\n","\n","mpl.find_output_cell = function(html_output) {\n","    // Return the cell and output element which can be found *uniquely* in the notebook.\n","    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n","    // IPython event is triggered only after the cells have been serialised, which for\n","    // our purposes (turning an active figure into a static one), is too late.\n","    var cells = IPython.notebook.get_cells();\n","    var ncells = cells.length;\n","    for (var i=0; i<ncells; i++) {\n","        var cell = cells[i];\n","        if (cell.cell_type === 'code'){\n","            for (var j=0; j<cell.output_area.outputs.length; j++) {\n","                var data = cell.output_area.outputs[j];\n","                if (data.data) {\n","                    // IPython >= 3 moved mimebundle to data attribute of output\n","                    data = data.data;\n","                }\n","                if (data['text/html'] == html_output) {\n","                    return [cell, data, j];\n","                }\n","            }\n","        }\n","    }\n","}\n","\n","// Register the function which deals with the matplotlib target/channel.\n","// The kernel may be null if the page has been refreshed.\n","if (IPython.notebook.kernel != null) {\n","    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n","}\n"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<div id='a3d84f76-08cf-41e0-b2f8-0dda281df16b'></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9011\n"]}]}]}