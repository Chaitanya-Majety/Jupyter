{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sNKZq4XrXQh"
   },
   "source": [
    "# <font color='red'><b>Bootstrap assignment</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAHap1Z3FZC-"
   },
   "source": [
    "<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n",
    "\n",
    "Every Grader function has to return True.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cuxBq_bvrwh2"
   },
   "source": [
    "<font color='blue'> <b>Importing packages</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6ag91ijrQOs"
   },
   "outputs": [],
   "source": [
    "import numpy as np # importing numpy for numerical computation\n",
    "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
    "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CcHOsONTt1K_"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pc1htEFYuLRj",
    "outputId": "f5b60712-98b3-4cdc-b629-3546c1e3859c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "kQle3T_wuOa3",
    "outputId": "521c7bdd-5316-48d5-c534-b61d170d2c28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
       "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
       "        1.5300e+01, 3.9690e+02, 4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9690e+02, 9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9283e+02, 4.0300e+00],\n",
       "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9463e+02, 2.9400e+00],\n",
       "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9690e+02, 5.3300e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEa_HqRZloH4"
   },
   "source": [
    "## <font color='red'><b>Task 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQ5q8IxHNRk3"
   },
   "source": [
    "<font color='red'> <b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJCFCaOzl7Mr"
   },
   "source": [
    "*  <font color='blue'><b>Creating samples</b></font><br>\n",
    "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
    "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
    "    \n",
    "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
    "* <font color='blue'><b> Create 30 samples </b></font>\n",
    "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
    "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
    "Make sure each sample will have atleast 3 feautres/columns/attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUqFEBSvNjCa"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uqi9AhCYNq3Z"
   },
   "source": [
    "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lLBnZHXOFln"
   },
   "source": [
    "*  Build a regression trees on each of 30 samples.\n",
    "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
    "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kls23JLnSN23"
   },
   "source": [
    "<font color='red'> <b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rz2GchkGSWnh"
   },
   "source": [
    "*  <font color='blue'><b>Calculating the OOB score </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DGHkVV2kSibm"
   },
   "source": [
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
    "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK860ocxTyoz"
   },
   "source": [
    "# <font color='red'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dme-N6TUCrY"
   },
   "source": [
    "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
    "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
    "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
    "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
    "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
    "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6UcH1x9Uwrj"
   },
   "source": [
    "# <font color='red'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOC_AgsLU7OH"
   },
   "source": [
    "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYs5jSFdVILe"
   },
   "source": [
    "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
    "Predict the house price for this point as mentioned in the step 2 of Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6gxZEsFWm-8"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2fHTdS_zpgG"
   },
   "source": [
    "# <font color='blue'> <b>Task - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0yGBuryOwHz"
   },
   "source": [
    "<font color='blue'><b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lJXX8vf3z073"
   },
   "source": [
    "*  <font color='blue'> <b>Creating samples</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSVaWG1F4uCZ"
   },
   "source": [
    "<font color='Orange'><b>Algorithm</b></font>\n",
    "\n",
    "![alt text](https://i.imgur.com/BTVYXQ1.jpg/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_oWoN97BhDY"
   },
   "source": [
    "*  <font color='blue'><b> Write code for generating samples</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ph_6D2SDzz7F"
   },
   "outputs": [],
   "source": [
    "def generating_samples(input_data, target_data):\n",
    "\n",
    "    '''In this function, we will write code for generating 30 samples '''\n",
    "    # you can use random.choice to generate random indices without replacement\n",
    "    # Please have a look at this link https://docs.scipy.org/doc/numpy-1.16.0/reference/generated/numpy.random.choice.html for more details\n",
    "    # Please follow above pseudo code for generating samples\n",
    "    selecting_rows = np.random.choice(len(input_data),303,replace=False) # 60% of 506\n",
    "    replacing_rows = np.random.choice(len(selecting_rows),203,replace=False) # ~40% of 506\n",
    "    idx = np.random.choice(list(range(3,input_data.shape[1]+1)),1)\n",
    "    selecting_columns = np.random.choice(input_data.shape[1],idx[0],replace=False) # column size must be >=3 and <13\n",
    "    # for a individual row multiple column should be selected, so we put like this\n",
    "    sample_data = input_data[selecting_rows[:,None],selecting_columns]\n",
    "    target_of_sample_data = target_data[selecting_rows]\n",
    "    \n",
    "    replicated_sample_data = sample_data[replacing_rows]\n",
    "    target_of_replicated_sample_data = target_of_sample_data[replacing_rows]\n",
    "    \n",
    "    final_sample_data = np.vstack((sample_data,replicated_sample_data))\n",
    "    final_target_data = np.vstack((target_of_sample_data.reshape(-1,1),target_of_replicated_sample_data.reshape(-1,1)))\n",
    "\n",
    "    return list(final_sample_data),list(final_target_data),list(selecting_rows),list(selecting_columns)\n",
    "    #note please return as lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MivEQFlm7iOg"
   },
   "source": [
    "<font color='cyan'> <b> Grader function - 1 </b> </fongt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVvuhNzm7uld"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_samples(a,b,c,d):\n",
    "    length = (len(a)==506  and len(b)==506)\n",
    "    sampled = (len(a)-len(set([str(i) for i in a]))==203)\n",
    "    rows_length = (len(c)==303)\n",
    "    column_length= (len(d)>=3)\n",
    "    assert(length and sampled and rows_length and column_length)\n",
    "    return True\n",
    "a,b,c,d = generating_samples(x, y)\n",
    "grader_samples(a,b,c,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4LSsmn4Jn2_"
   },
   "source": [
    "*  <font color='blue'> <b>Create 30 samples </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ec7MN6sL2BZ"
   },
   "source": [
    "![alt text](https://i.imgur.com/p8eZaWL.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXlKWjCcBvTk"
   },
   "outputs": [],
   "source": [
    "# Use generating_samples function to create 30 samples \n",
    "# store these created samples in a list\n",
    "list_input_data =[]\n",
    "list_output_data =[]\n",
    "list_selected_row= []\n",
    "list_selected_columns=[]\n",
    "\n",
    "for i in range(0,30):\n",
    "    a,b,c,d = generating_samples(x,y)\n",
    "    list_input_data.append(a)\n",
    "    list_output_data.append(b)\n",
    "    list_selected_row.append(c)\n",
    "    list_selected_columns.append(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXUz9VFiMQkh"
   },
   "source": [
    "<font color='cyan'> <b>Grader function - 2 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCvIq8NuMWOC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_30(a):\n",
    "    assert(len(a)==30 and len(a[0])==506)\n",
    "    return True\n",
    "grader_30(list_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Pv-mkZkO6dh"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whaHCPB0O8qF"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBy4zXSWPtU8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for building tree</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xvH06HPQBdP"
   },
   "source": [
    "![alt text](https://i.imgur.com/pcXfSmp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRwPO_uHQjul"
   },
   "source": [
    "*  <font color='blue'><b> Write code for building regression trees</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWQp6tRwMthq"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "list_of_all_models = []\n",
    "dummy_models = []\n",
    "for i in range(0,30):\n",
    "    dummy_models.append(\"clf\"+str(i))\n",
    "for i in range(0,30):\n",
    "    dummy_models[i] = DecisionTreeRegressor(max_depth=None) #for getting more overfit model\n",
    "    dummy_models[i].fit(list_input_data[i],list_output_data[i])\n",
    "    list_of_all_models.append(dummy_models[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21j8BKfAQ1U8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating MSE </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Q0mTBD2RBx_"
   },
   "source": [
    "![alt text](https://i.imgur.com/sPEE618.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6e-UamlHRjPy"
   },
   "source": [
    "After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TnIMT7_oR312"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating MSE</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qWhcvMRWRA9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square error: 0.12433794466403164\n"
     ]
    }
   ],
   "source": [
    "predicted_each_model_y = []\n",
    "total_predicted = []\n",
    "\n",
    "# Here we predict 506 data points in our actual data taken from boston across all 30 models\n",
    "# As we are passing our original data, column sampling should be seen carefully\n",
    "# So for each model, we will get 506 predicted outputs\n",
    "# so totally we will have 30*506 shaped array\n",
    "for i in range(0,30):\n",
    "    predicted_each_model_y =[]\n",
    "    for j in range(0,506):\n",
    "        temp = dummy_models[i].predict(np.array(x[j][list_selected_columns[i]].reshape(1,-1)))\n",
    "        predicted_each_model_y.append(temp[0])\n",
    "    total_predicted.append(predicted_each_model_y)\n",
    "\n",
    "# so in that 30*506 shaped array, \n",
    "## in the 0th row - we will have prediction for 1st data point across each model\n",
    "## similarly, in the 1st row - we will have prediction for 2nd data point across each model\n",
    "\n",
    "# so, by this understanding we can add all of them in a parallel basis\n",
    "# converting into arrays for simple addition of elements in a element wise manner\n",
    "# So at the end of this, we will get an 1*506 array, which will have median of predict values\n",
    "# that came from all the models\n",
    "\n",
    "pred_array = np.median(np.asarray(total_predicted),axis=0)\n",
    "\n",
    "# Here, one key point is actual data will not change for each model, its constant through out\n",
    "# so no need of calculations for actual y values\n",
    "# For calculating MSC\n",
    "mse = 0\n",
    "for i in range(len(y)):\n",
    "    mse += ((y[i]-pred_array[i])**2)  \n",
    "mse/=len(y)\n",
    "print(\"Mean Square error:\",mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RuclPDMnSz8F"
   },
   "source": [
    "<font color='blue'><b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESb9FSIDTM5V"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating OOB score</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HB-d6NMETbd9"
   },
   "source": [
    "![alt text](https://i.imgur.com/95S5Mtm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WW3GOcFzTqbt"
   },
   "source": [
    "Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zBqcS03pUYSZ"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating OOB score </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fog_6DNdS-h_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOBS score: 16.553152173913045\n"
     ]
    }
   ],
   "source": [
    "# Remember - each model is built on sample, so count of samples = count of models\n",
    "final_temp = []\n",
    "# listing down where does each data point not part of the sample\n",
    "# at end of each i value, we get the models(samples) which that data point is not part of.\n",
    "for i in range(0,506):\n",
    "    temp=[]\n",
    "    for j in range(0,30):\n",
    "        if i not in list_selected_row[j]:\n",
    "            temp.append(j)\n",
    "    final_temp.append(temp)        \n",
    "\n",
    "# Now we got the samples(models) for each datapoint which its not part of\n",
    "# so we can find predictions on that models alone for each data point\n",
    "oobs_final = []\n",
    "for i in range(len(final_temp)):\n",
    "    oobs_each = []\n",
    "    for j in final_temp[i]:\n",
    "        oobs_each.append(dummy_models[j].predict(np.array(x[i][list_selected_columns[j]].reshape(1,-1))))\n",
    "    med = np.median(oobs_each)\n",
    "    oobs_final.append(med)\n",
    "\n",
    "# Now same like MSE calculate the OOBS score\n",
    "oobs = 0\n",
    "for i in range(0,506):\n",
    "    oobs+=((oobs_final[i]-y[i])**2)\n",
    "\n",
    "oobs/=len(y)\n",
    "print(\"OOBS score:\",oobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**<br>\n",
    "*1. Here OOB score will helpful because it will give the approximation of error in a better way because when we are calculating OOB score, we are not touching the models taht includes the data point and only caring on the models where there is no data point and calculating the predicted value & then taking the median from only those boot strapped samples*<br>\n",
    "*2. Where as in MSE score, we will consider all the models predicted output, so there will be chance of increasing the error for a future data point and it will be hard to trust the MSE score got from the bootstrapped samples*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbuiwX3OUjUI"
   },
   "source": [
    "# <font color='blue'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ceW5-D88Uswi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Train MSE scores: [0.23584609683794466, 0.13140933794466408, 0.024249011857707548, 0.12255434782608701, 0.06521638299588609, 0.05632411067193672, 0.04359189723320159, 0.07569717640009059, 0.25922357742591845, 0.0723350680720246, 0.022099802371541497, 0.2764113416470639, 0.052187835480407944, 0.09988735177865607, 0.06590415019762844, 0.08437527454479751, 0.09640143551526219, 0.03560400197628455, 0.06577294685990334, 0.11817637994351338, 0.07013833992094866, 0.12581027667984182, 0.03155632411067191, 0.10968379446640321, 0.06948342116820376, 0.04857707509881423, 0.09922430830039525, 0.018739015151515142, 0.05561758893280635, 0.06230854743083006, 0.10360464568367446, 0.06466403162055342, 0.034584053853754945, 0.08915598193577898, 0.11457894158981109]\n",
      "List of OOB scores: [12.35296882411067, 13.434189185074247, 12.283552371541496, 15.173513043478257, 14.085285551434902, 14.286554545454543, 15.386329051383402, 13.308660428626961, 13.875009556383496, 15.132301987526974, 11.959471146245056, 13.920232225665053, 13.812912894749676, 13.841435053545744, 12.25328063241106, 13.864216154078408, 15.873347605486414, 13.488643097676274, 13.168876751207732, 12.172159549586214, 12.035937439613525, 13.645000452730491, 11.167765150481943, 15.91651185770752, 11.757381422924894, 11.173332324614126, 14.301759442248565, 12.51002195465407, 14.805496539031656, 14.408698038863745, 14.34309679025005, 13.112838747529649, 12.810118165349149, 16.172210838198048, 13.054827075098814]\n"
     ]
    }
   ],
   "source": [
    "## Taking all the necessary modules from the previous sections\n",
    "\n",
    "def clt_data(x,y):\n",
    "    \n",
    "    list_input_data =[]\n",
    "    list_output_data =[]\n",
    "    list_selected_row= []\n",
    "    list_selected_columns=[]\n",
    "\n",
    "    for i in range(0,30):\n",
    "        a,b,c,d = generating_samples(x,y)\n",
    "        list_input_data.append(a)\n",
    "        list_output_data.append(b)\n",
    "        list_selected_row.append(c)\n",
    "        list_selected_columns.append(d)\n",
    "        \n",
    "    list_of_all_models = []\n",
    "    dummy_models = []\n",
    "    for i in range(0,30):\n",
    "        dummy_models.append(\"clf\"+str(i))\n",
    "    for i in range(0,30):\n",
    "        dummy_models[i] = DecisionTreeRegressor(max_depth=None) #for getting more overfit model\n",
    "        dummy_models[i].fit(list_input_data[i],list_output_data[i])\n",
    "        list_of_all_models.append(dummy_models[i])\n",
    "    \n",
    "    #### MSE Block ####\n",
    "    predicted_each_model_y = []\n",
    "    total_predicted = []\n",
    "    for i in range(0,30):\n",
    "        predicted_each_model_y =[]\n",
    "        for j in range(0,506):\n",
    "            temp = dummy_models[i].predict(np.array(x[j][list_selected_columns[i]].reshape(1,-1)))\n",
    "            predicted_each_model_y.append(temp[0])\n",
    "        total_predicted.append(predicted_each_model_y)\n",
    "\n",
    "    pred_array = np.median(np.asarray(total_predicted),axis=0)\n",
    "\n",
    "    mse = 0\n",
    "    for i in range(len(y)):\n",
    "        mse += ((y[i]-pred_array[i])**2)  \n",
    "    mse/=len(y)\n",
    "    \n",
    "    #### OOBS Block ####\n",
    "    final_temp = []\n",
    "    for i in range(0,506):\n",
    "        temp=[]\n",
    "        for j in range(0,30):\n",
    "            if i not in list_selected_row[j]:\n",
    "                temp.append(j)\n",
    "        final_temp.append(temp)        \n",
    "\n",
    "    oobs_final = []\n",
    "    for i in range(len(final_temp)):\n",
    "        oobs_each = []\n",
    "        for j in final_temp[i]:\n",
    "            oobs_each.append(dummy_models[j].predict(np.array(x[i][list_selected_columns[j]].reshape(1,-1))))\n",
    "        med = np.median(oobs_each)\n",
    "        oobs_final.append(med)\n",
    "\n",
    "    oobs = 0\n",
    "    for i in range(0,506):\n",
    "        oobs+=((oobs_final[i]-y[i])**2)\n",
    "\n",
    "    oobs/=len(y)\n",
    "    \n",
    "    return mse,oobs\n",
    "\n",
    "train_mse = []\n",
    "oob_score = []\n",
    "for i in range(0,35):\n",
    "    mse,oobs = clt_data(x,y)\n",
    "    train_mse.append(mse)\n",
    "    oob_score.append(oobs)\n",
    "    \n",
    "print(\"List of Train MSE scores:\",train_mse)\n",
    "print(\"List of OOB scores:\",oob_score)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C.I for train_MSE: [0.06798186869035976, 0.10921778122532731]\n",
      "C.I for OOB score: [13.12109769275497, 14.015355786957192]\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "mean_train = np.mean(np.asarray(train_mse))\n",
    "mean_oob = np.mean(np.asarray(oob_score))\n",
    "\n",
    "stderr_train = st.sem(np.asarray(train_mse))\n",
    "stderr_oob = st.sem(np.asarray(oob_score))\n",
    "\n",
    "# Assuming given Confidence-level is 0.95\n",
    "# so what ever we consider will lie in [<mean/std>-2*(sigma/sqrt(n)),<mean/std>+2*(sigma/sqrt(n))]\n",
    "\n",
    "train_ci_lower = mean_train-(2*stderr_train)\n",
    "train_ci_upper = mean_train+(2*stderr_train)\n",
    "train_ci=[train_ci_lower,train_ci_upper]\n",
    "print(\"C.I for train_MSE:\",train_ci)\n",
    "oob_ci_lower = mean_oob-(2*stderr_oob)\n",
    "oob_ci_upper = mean_oob+(2*stderr_oob)\n",
    "oob_ci=[oob_ci_lower,oob_ci_upper]\n",
    "print(\"C.I for OOB score:\",oob_ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**<br>\n",
    "*1. By these scores, we can say that 95% of the times, actual population train_MSE will lie in the range of (0.06798186869035976, 0.10921778122532731)*<br>\n",
    "*2. where as, actual population OOB_score will lie in the range of (13.12109769275497, 14.015355786957192)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKTnJdiBVS_e"
   },
   "source": [
    "# <font color='blue'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXxrvZqHV1Fr"
   },
   "source": [
    "<font color='orange'><b>Flowchart for Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyjwEJ62V6a6"
   },
   "source": [
    "<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0emSwLL7VurD"
   },
   "source": [
    "![alt text](https://i.imgur.com/Y5cNhQk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29hjwKlWWDfo"
   },
   "source": [
    "*  <font color='blue'><b> Write code for TASK 3 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_pUlSD-VYD1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted output for given xq: 18.5\n"
     ]
    }
   ],
   "source": [
    "xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60]\n",
    "yq = []\n",
    "for i in range(0,30):\n",
    "    temp = dummy_models[i].predict(np.asarray(xq)[list_selected_columns[i]].reshape(1,-1))\n",
    "    yq.append(temp[0])\n",
    "\n",
    "predicted_yq = np.median(yq)\n",
    "print(\"The predicted output for given xq:\",predicted_yq)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bootstrap_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
